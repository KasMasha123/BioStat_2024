---
title: "ДЗ по автоматизации данных в R"
author: "Касьянова Мария"
date: "`r Sys.Date()`"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, error = FALSE, warning = FALSE)

library(tidyverse)
library(stringi)
library(ggbeeswarm)
library(RColorBrewer)
library(ggpubr)
#library("flextable")
```

# Чтение данных

В вашем варианте нужно использовать датасет food.

```{r}
food <- read.csv("./data/raw/food.csv")
```

# Выведите общее описание данных

Информцию про датасет можно найти по ссылке: https://www.kaggle.com/datasets/mexwell/food-vitamins-minerals-macronutrient. Большинство переменных являются количественными. Посмотрим на краткую характеристику:

```{r}
glimpse(food)
```
Также можно узнать чуть больше при помощи функции summary:

```{r}
summary(food)
```

# Очистка данных

1) Уберите переменные, в которых пропущенных значений больше 20% или уберите субъектов со слишком большим количеством пропущенных значений. Или совместите оба варианта. Напишите обоснование, почему вы выбрали тот или иной вариант.

Сначала посмотрим, сколько пропущенных значений есть в нашей таблице:

```{r}
sum(is.na(food))
```

**Обоснование**: Мы видим, что их нет, значит дополнительно преобразовывать таблицу не нужно (иногда пропущенные значения неправильно отображаются, если, например, их обозначают знаком "-" или 0. Однако в этих данных все переменные, которые должны быть численными, считываются корректно, значит в клетках не встречается нечисленных символов. И значение 0 является обычным измерением, ведь в каких-то продуктах могут отсутсвовать определенные элементы). 

 Но если бы в данных были пропущенные значения, я бы могла выбрать разные тактики работы с ними в зависимости от поставленной задачи и паттерна их распределения по столбцам и строкам (если нам хватает измерений, то лучше удалить строки, чем потерять целый фактор для анализа, но если измерений немного и большая часть пропущенных значений в одном столбце, то лучше удалить этот столбец и иметь возможность изучить все остальные переменные на достаточной количестве строк)


2) Переименуйте переменные в человекочитаемый вид (что делать с пробелами в названиях?);

3) В соответствии с описанием данных приведите переменные к нужному типу (numeric или factor);

4) Отсортируйте данные по углеводам по убыванию;

5) Сохраните в файл outliers.csv субъектов, которые являются выбросами (например, по правилу трёх сигм) — это необязательное задание со звёздочкой;

6) Отфильтруйте датасет так, чтобы остались только Rice и Cookie (переменная Category и есть группирующая);

7) Присвойте получившийся датасет переменной "cleaned_data".

```{r}
cleaned_data <- food %>% 
  mutate(across(c(Category, Description, Nutrient.Data.Bank.Number), ~ as.factor(.x))) %>% 
  rename_with(function(x) x %>% stri_replace_all_regex(c("Data.", "Fat.", "Vitamins.", "Major.Minerals.", "\\."), c("", "", "", "", " "), vectorize_all = FALSE)) %>%
  rename('Nutrient Data Bank Number' = 'Nutrient Bank Number')%>%
  arrange(desc(Carbohydrate)) %>%
  filter(Category %in% c("Rice", "Cookie"))
```

# Сколько осталось переменных?

```{r}
ncol(cleaned_data)
```

# Сколько осталось случаев?

```{r}
nrow(cleaned_data)
```

# Есть ли в данных идентичные строки?

```{r}
nrow(cleaned_data) - nrow(distinct(cleaned_data))

```
Нет

# Сколько всего переменных с пропущенными значениями в данных и сколько пропущенных точек в каждой такой переменной?

```{r}
cleaned_data %>% 
  mutate(across(where(is.numeric), ~ as.character(.x))) %>% 
  pivot_longer(colnames(cleaned_data), names_to = "Variable")%>%
  group_by(Variable)%>%
  summarise('Number of NA'= sum(is.na(value)))%>%
  filter(`Number of NA` != 0)
```

Приведенный код вывел бы переменные с пропущенными значениями, а также количество этих значений, однако в таблице они отсутсвуют.

# Описательные статистики

## Количественные переменные

1) Рассчитайте для всех количественных переменных для каждой группы (Category):

1.1) Количество значений;

1.2) Количество пропущенных значений;

1.3) Среднее;

1.4) Медиану;

1.5) Стандартное отклонение;

1.6) 25% квантиль и 75% квантиль;

1.7) Интерквартильный размах;

1.8) Минимум;

1.9) Максимум;

1.10) 95% ДИ для среднего - задание со звёздочкой.

```{r}
numeric_stat_table <- cleaned_data %>% 
  pivot_longer(!c(Category, Description, 'Nutrient Data Bank Number'), names_to = 'Variable')%>%
  group_by(Category,Variable)%>%
  summarise('Number of values'= n(),
            'Number of NA' = sum(is.na(value)),
            Mean = mean(value),
            Median = median(value),
            'Standart Deviation' = sd(value),
            Q25 = quantile(value, 0.25),
            Q75 = quantile(value, 0.75),
            IQR = quantile(value, 0.75)- quantile(value, 0.25),
            Min = min(value),
            Max = max(value))

numeric_stat_table %>% head()
```

## Категориальные переменные

1) Рассчитайте для всех категориальных переменных для каждой группы (Category):

1.1) Абсолютное количество;

1.2) Относительное количество внутри группы;

1.3) 95% ДИ для доли внутри группы - задание со звёздочкой.

```{r}
factor_stat_table <- cleaned_data %>% 
  select(c(Category, Description))%>%
  count(Category, Description)%>%
  group_by(Category)%>%
  mutate('Percentage of сategory' = str_c(round(n/sum(n)*100, 2), "%"))%>%
  rename('Number of cases' = n) 

factor_stat_table
```

# Визуализация

## Количественные переменные

1) Для каждой количественной переменной сделайте боксплоты по группам. Расположите их либо на отдельных рисунках, либо на одном, но читаемо;

2) Наложите на боксплоты beeplots - задание со звёздочкой.

3) Раскрасьте боксплоты с помощью библиотеки RColorBrewer.

Можно построить все боксплоты сразу при помощи facet_wrap, но в таком случае на всех графиках будут одинаковые пределы осей. К сожалению, переменные в данном датасете сильно отличаются друг от друга, поэтому сравнение их друг с другом затруднительно:

```{r, fig.width = 16, fig.height= 16}
cleaned_data %>% 
  select(Category, where(is.numeric))%>% 
  pivot_longer(!Category)%>%
  ggplot(aes(y = value, x = Category, fill = Category))+
  geom_boxplot()+

  theme_bw()+
  theme(
    axis.text.x = element_text(size = 10)
  )+
  labs(x = "",
       y = "")+
  facet_wrap(~name)+
  scale_fill_manual(values = brewer.pal(2, "Set1"))
```

Можно построить аналогичные графики для каждой переменной независимо, в таком случае переменные будет трудно сравнивать друг с другом, зато боксплоты будут в большинстве своем информативны


```{r, fig.width = 16, fig.height=16}
x <- cleaned_data %>% 
  select(where(is.numeric))%>%
  colnames()

list_of_plots <- list()

for (i in x){
  plot <- cleaned_data %>% 
  select(Category, i)%>% 
  pivot_longer(!Category)%>%
  ggplot(aes(y = value, x = Category, fill = Category))+
  geom_boxplot(outliers = FALSE)+
  geom_quasirandom(color = "lightgray", shape = 1)+
  theme_bw()+
  theme(
    axis.text.x = element_text(size = 10),
    legend.position = "None"
  )+
  labs(x = "",
       y = "")+
  facet_grid(~name)+
  scale_fill_manual(values = brewer.pal(2, "Set1"))
  
  list_of_plots = c(list_of_plots, list(plot))
}

ggarrange(plotlist = list_of_plots,
          nrow = 5,
          ncol = 7)
```


## Категориальные переменные

1) Сделайте подходящие визуализации категориальных переменных. Обоснуйте, почему выбрали именно этот тип.

Единственная категориальная переменная, которую имеет смысл визуализировать - это категория продукта (их всего две). Можно показать количество записей в каждой из двух категорий с помощью столбиковой диаграммы или долю записей в каждой атегории от общего количества.

```{r}
cleaned_data %>% 
  ggplot(aes(x = Category, fill = Category))+
  geom_bar()+
  theme_bw()+
  theme(legend.position = "None")+
  labs(x = "")+
  scale_fill_manual(values = brewer.pal(2, "Set1"))
```

# Статистические оценки

## Проверка на нормальность

1) Оцените каждую переменную на соответствие нормальному распределению с помощью теста Шапиро-Уилка. Какие из переменных являются нормальными и как как вы это поняли?

```{r}
cleaned_data %>% 
  pivot_longer(!c(Category, Description, 'Nutrient Data Bank Number'), names_to = "Nutrient")%>%
  group_by(Nutrient)%>%
  summarise('p value' = shapiro.test(value)$p.value*35)%>%
  arrange(desc(`p value`))
```

Тест Шапиро-Уилка проверяет нулевую гипотезу о нормальности распределения. Если p-value меньше 0.05, но эту гипотезу необходимо отвергнуть и считать распределение не нормальным. В данном случе даже с поправкой на множественное тестирование гипотеза о нормальности отклоняется во всех случаях (наибольшее значение меньше 5%).

2) Постройте для каждой количественной переменной QQ-плот. Отличаются ли выводы от теста Шапиро-Уилка? Какой метод вы бы предпочли и почему?

Выводы не отличаются, я бы предпочла тест Шапиро-Уилка, так как QQ-плот оценивается визуально, из-за чего не является точным методом, особенно если нужно проверять нормальность 35 переменных за раз (но можно использовать его как первичный метод анализа, результаты которого будут дополнительно подтверждены тестом Шапиро-Уилка). 

```{r, fig.width = 16, fig.height=16}
x <- cleaned_data %>% 
  select(where(is.numeric))%>%
  colnames()

list_of_plots <- list()

for (i in x){
  plot <- cleaned_data %>% 
  select(Category, i)%>% 
  pivot_longer(!Category)%>%
  ggplot(aes(sample = value))+
  facet_grid(~name)+
  stat_qq() + 
  stat_qq_line()+
  theme_bw() 
  
  
  list_of_plots = c(list_of_plots, list(plot))
}

ggarrange(plotlist = list_of_plots,
          nrow = 5,
          ncol = 7)
```

3) Ниже напишите, какие ещё методы проверки на нормальность вы знаете и какие у них есть ограничения.

**Напишите текст здесь**
Критерий Колмогорова-Смирного: применяется для больших размеров выборок (>50)


## Сравнение групп

1) Сравните группы (переменная **Category**) по каждой переменной (как количественной, так и категориальной). Для каждой переменной выберите нужный критерий и кратко обоснуйте его выбор в комментариях.

В данном датасете помимо переменной  **Category** есть описание (Description) и номер в банке (Nutrient Data Bank Number), которые являются уникальными для каждой записи. Сравнивать их между двумя группами не представляется возможным (и осмысленным). Единственная категориальная переменная - это сама **Category**, сравнить ее можно лишь по количеству записей в каждой из двух групп, что уже было сделано ранее. Остается еще 35 количественных переменных, отражающих содержание различных ингридиентов и микроэлементов в рисе и печенье. Можно для каждого ингридиента проверить, различается ли его среднее содержание в этих двух продуктах или нет. Мы уже поняли, что данные имеют ненормальное распределение, поэтому использовать можно только непараметрические тесты, например, тест Манна-Уитни. При этом нужно не забыть поправку на множественное тестирование. Почти для всех ингридиентов можно отвертгуть нулевую гипотезу о равенстве средних 

```{r}
cleaned_data %>% 
  pivot_longer(!c(Category, Description, 'Nutrient Data Bank Number'), names_to = "Nutrient")%>%
  group_by(Nutrient)%>%
  summarise('p value adjusted' = wilcox.test(value ~ Category)$p.value*35)%>%
  arrange(desc(`p value adjusted`))
 # flextable::flextable()
```
Гипотеза не отвергается всего для трех ингридиентов: 

```{r}
cleaned_data %>% 
  select(Category, Cholesterol, `Beta Cryptoxanthin`, Zinc)%>% 
  pivot_longer(!Category)%>%
  ggplot(aes(y = value, x = Category, fill = Category))+
  geom_boxplot(outliers = FALSE)+
  theme_bw()+
  theme(
    axis.text.x = element_text(size = 10),
    legend.position = "None"
  )+
  labs(x = "",
       y = "")+
  facet_grid(~name)+
  scale_fill_manual(values = brewer.pal(2, "Set1"))
```



# Далее идут **необязательные** дополнительные задания, которые могут принести вам дополнительные баллы в том числе в случае ошибок в предыдущих

## Корреляционный анализ

1) Создайте корреляционную матрицу с визуализацией и поправкой на множественные сравнения. Объясните, когда лучше использовать корреляционные матрицы и в чём минусы и плюсы корреляционных исследований.

```{r}



```

## Моделирование

1) Постройте регрессионную модель для переменной **Category**. Опишите процесс построения

```{r}

```